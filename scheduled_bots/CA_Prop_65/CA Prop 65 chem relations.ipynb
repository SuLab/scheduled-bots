{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CA Prop 65 Chemical categorization\n",
    "California Proposition 65 requires labeling for chemical acknowledged in the state of California as causing cancer or reproductive/developmental toxicity. This enables us to categorize the chemicals on the Prop 65 list as instances of 'carcinogen', 'reproductive toxicant', 'male reproductive toxicant', 'female reproductive toxicant', and 'developmental toxicant' in Wikidata adding some very basic (and somewhat indirect) chem-disease relationships\n",
    "\n",
    "Note that California's OEHHA allows users to download a pre-exported .csv file of chemicals listed under Prop 65 (does not include de-listed chemicals). Alternatively, users can export the complete list of chemicals from OEHHA which will include chemicals that are under consideration, currently listed, or formerly listed.\n",
    "\n",
    "This notebook partially explores both exports for the best way for loading the data into Wikidata. The final bot will likely NOT include both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidataintegrator import wdi_core, wdi_login, wdi_helpers\n",
    "from wikidataintegrator.ref_handlers import update_retrieved_if_new_multiple_refs\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import requests\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import ipywidgets \n",
    "import widgetsnbextension\n",
    "import xml.etree.ElementTree as et \n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import copy\n",
    "def create_reference(prop65_url):\n",
    "    refStatedIn = wdi_core.WDItemID(value=\"Q28455381\", prop_nr=\"P248\", is_reference=True)\n",
    "    timeStringNow = datetime.now().strftime(\"+%Y-%m-%dT00:00:00Z\")\n",
    "    refRetrieved = wdi_core.WDTime(timeStringNow, prop_nr=\"P813\", is_reference=True)\n",
    "    refURL = wdi_core.WDUrl(value=prop65_url, prop_nr=\"P854\", is_reference=True)\n",
    "\n",
    "    return [refStatedIn, refRetrieved, refURL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Login for Scheduled bot\n",
    "print(\"Logging in...\")\n",
    "try:\n",
    "    from scheduled_bots.local import WDUSER, WDPASS\n",
    "except ImportError:\n",
    "    if \"WDUSER\" in os.environ and \"WDPASS\" in os.environ:\n",
    "        WDUSER = os.environ['WDUSER']\n",
    "        WDPASS = os.environ['WDPASS']\n",
    "    else:\n",
    "        raise ValueError(\"WDUSER and WDPASS must be specified in local.py or as environment variables\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logging in...\")\n",
    "import wdi_user_config ## Credentials stored in a wdi_user_config file\n",
    "login_dict = wdi_user_config.get_credentials()\n",
    "login = wdi_login.WDLogin(login_dict['WDUSER'], login_dict['WDPASS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up logging\n",
    "\n",
    "wdi_core.WDItemEngine.setup_logging(header=json.dumps({'name': 'prop_65', \n",
    "                                                       'timestamp': str(datetime.now()), \n",
    "                                                       'run_id': str(datetime.now())}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the most recent csv file and parse it\n",
    "\n",
    "## Prop 65 list method\n",
    "The updates appear to be posted on this site: https://oehha.ca.gov/proposition-65/proposition-65-list\n",
    "Since the updated data file name changes depending on the update date, it would be nice if the newer file name could be scraped from this page instead of being hard-coded in. It would be nice if date could also be scraped from this page and used for comparison to determine if changes were made and if an update is needed.\n",
    "\n",
    "Unfortunately, this page uses iframes and is protected from robots using captchas (Incapsula), so the csv should be manually downloaded to the data folder and named by the update date (YYYY-MM-DD.csv) prior to running the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Chemical  \\\n",
      "1003                                   Zidovudine (AZT)   \n",
      "1004                                          Zileuton    \n",
      "1005  Zineb  Delisted October 29, 1999 [Click here f...   \n",
      "\n",
      "                   Type of Toxicity Listing Mechanism      CAS No.  \\\n",
      "1003                        cancer                 LC   30516-87-1   \n",
      "1004  cancer, developmental, female                FR  111406-87-2   \n",
      "1005                         cancer                AB   12122-67-7   \n",
      "\n",
      "     Date Listed NSRL or MADL (µg/day)a  \n",
      "1003   18-Dec-09                   None  \n",
      "1004   22-Dec-00                   None  \n",
      "1005    1-Jan-90                   None  \n"
     ]
    }
   ],
   "source": [
    "datasrc = 'data/2019-09-13.csv'\n",
    "\n",
    "header_junk = 11 ## Note, the number of rows to skip may change\n",
    "tail_junk = 6\n",
    "\n",
    "chem_list = read_csv(datasrc, skiprows=header_junk, encoding = 'unicode_escape') \n",
    "chem_list.dropna(axis='columns', how='all',inplace=True)\n",
    "chem_list.fillna(\"None\", inplace=True)\n",
    "chem_list.drop_duplicates(keep='first',inplace=True)\n",
    "## Filter out blank entries\n",
    "chem_list_clean = chem_list.loc[(chem_list['Chemical']!=\"None\")].copy()\n",
    "chem_list_clean.drop(chem_list_clean.tail(tail_junk).index,inplace=True)\n",
    "print(chem_list_clean.tail(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the csv table has sub-entries which appear as seperate entries, but should retain the header entry data except for the last field.  These will need to be accounted for. As of the csv file dated from 2019.09.13, these entries are preceded with some spaces. Another way to filter for them is to pull entries which have \"None\" for everything but 'chemical name' and 'NSRL or MADL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Chemical Type of Toxicity Listing Mechanism CAS No.  \\\n",
      "97            Beryllium              None              None    None   \n",
      "98       Beryllium oxide             None              None    None   \n",
      "99     Beryllium sulfate             None              None    None   \n",
      "\n",
      "   Date Listed NSRL or MADL (µg/day)a  \n",
      "97        None                    0.1  \n",
      "98        None                    0.1  \n",
      "99        None                 0.0002  \n",
      "22\n"
     ]
    }
   ],
   "source": [
    "sub_entries = chem_list_clean.loc[(chem_list_clean['Chemical'].str.contains(\"  \")) &\n",
    "                                  (chem_list_clean['Type of Toxicity']==\"None\") &\n",
    "                                  (chem_list_clean['Listing Mechanism']==\"None\")]\n",
    "print(sub_entries.head(n=3))\n",
    "print(len(sub_entries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual toxicity information for these sub-entries can actually be found in the header entry.  To find these, obtain the index values for these entries. If entries are sequential, the header-entry should be 1 less the smallest index value. The values could be copied over, though the CAS number should not be copied over.\n",
    "\n",
    "Alternatively, entries without CAS numbers can be assumed to have sub-entries and can be ignored, but doing this will skip entries which do have profiles, but not CAS numbers. Eg- Alcoholic Beverages which doesn't have a CAS No. but will likely be appropriately matched via Mix N Match. As a result, we should be able to cover cases like this even if it doesn't have a CAS number.\n",
    "\n",
    "That said, aggregate entries only have 1 prop 65 page and multiple Wikidata pages, which would result in one to many mappings. Since it's unclear how these will be handled by the Mix N match community, the first pass should ignore the aggregate entries (which can be identified as mentioned above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chemical names to URL conversion\n",
    "The property in Wikidata uses the URL stub as ID so we'll need to convert the Chemical names to url stubs that work with prop65 website. The urls will then be mapped to Wikidata entries with the property that were added via Mix N match. Normally, urls can be tested, but CA Prop 65 website has captcha protection and blocks scrapers.\n",
    "\n",
    "Also, note that the items that have been de-listed have urls, but their urls are no longer readily available (ie- the urls work, but are not necessarily listed)\n",
    "\n",
    "Example conversion:\n",
    "* \"A-alpha-C (2-Amino-9H-pyrido[2,3-b]indole)\" --> \"alpha-c-2-amino-9h-pyrido23-bindole\"\n",
    "* \"Altretamine\" --> \"altretamine\"\n",
    "* \"Allyl chloride  Delisted October 29, 1999 [Click here for the basis for delisting]\" --> \"allyl-chloride\"\n",
    "* \"p-Aminoazobenzene\" --> \"p-aminoazobenzene\"\n",
    "* \"4-Aminobiphenyl (4-aminodiphenyl)\" --> \"4-aminobiphenyl-4-aminodiphenyl\"\n",
    "* \"2-Amino-5-(5-nitro-2-furyl)-1,3,4-thiadiazole\" --> \"2-amino-5-5-nitro-2-furyl-134-thiadiazole\"\n",
    "* \"?-Methyl styrene (alpha-Methylstyrene)\" --> \"methyl-styrene-alpha-methylstyrene\"\n",
    "* \"N,N'-Diacetylbenzidine\" --> \"nn-diacetylbenzidine\"\n",
    "* \"MeIQx (2-Amino-3,8-dimethylimidazo[4,5-f]quinoxaline)\" --> \"meiqx-2-amino-38-dimethylimidazo45-fquinoxaline\"\n",
    "* \"2?Mercaptobenzothiazole\" --> \"2-mercaptobenzothiazole\"\n",
    "* \"Trp-P-1 (Tryptophan-P-1)\" --> \"trp-p-1-tryptophan-p-1\"\n",
    "* \"Alcoholic beverages, when associated with alcohol abuse\" --> \"alcoholic-beverages\"\n",
    "* \"Aspirin (NOTE:  It is especially  important not to use aspirin during the last three months of pregnancy,  unless specifically directed to do so by a physician because it may cause  problems in the unborn child or  complications during delivery.)\" --> \"aspirin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up miscellenous notes included in the chemical names such as 'delistings, delisting dates, changes in listings'. This should be added as deprecation of the statements. \n",
    "\n",
    "Because of all these issues, we'll work with the OEHHA list rather than the Prop 65 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CA OEHHA clean up method\n",
    "The manually triggered export of chemical list from the OEHHA site has less header junk, random title notes, and other things that disrupt the structure which would make the name convers easier. Additionally, the data on the cancer, reproductive toxicity, etc. is more structured, and doesn't have random blank spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasrc = 'data/OEHHA-2019-11-1.csv'\n",
    "\n",
    "chem_list = read_csv(datasrc, encoding = 'unicode_escape', header=0) \n",
    "chem_list.dropna(axis='columns', how='all',inplace=True)\n",
    "chem_list.fillna(\"None\", inplace=True)\n",
    "#print(chem_list.columns.values)\n",
    "\n",
    "## Pull out only columns of interest for our task\n",
    "cols_of_interest = chem_list[['Title','CAS Number','Cancer','Cancer - Listing Mechanism',\n",
    "                          'Reproductive Toxicity','Chemical listed under Proposition 65 as causing',\n",
    "                          'Developmental Toxicity - Date of Listing','Developmental Toxicity - Listing Mechanism',\n",
    "                          'Female Reproductive Toxicity - Date of Listing',\n",
    "                          'Female Reproductive Toxicity - Listing Mechanism',\n",
    "                          'Male Reproductive Toxicity - Date of Listing',\n",
    "                          'Male Reproductive Toxicity - Listing Mechanism']]\n",
    "\n",
    "## Remove entries which are not relevant\n",
    "prop_65_irrelevant = cols_of_interest.loc[(cols_of_interest['Cancer'] == \"None\") & \n",
    "                                          (cols_of_interest['Reproductive Toxicity'] == \"None\") & \n",
    "                                          (cols_of_interest['Chemical listed under Proposition 65 as causing'] == \"None\")]\n",
    "non_prop_chems = prop_65_irrelevant['Title'].tolist()\n",
    "prop65_chems = cols_of_interest.loc[~cols_of_interest['Title'].isin(non_prop_chems)].copy()\n",
    "#print(prop65_chems.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chemical names to URL conversion\n",
    "The property in Wikidata uses the URL stub as ID so we'll need to convert the Chemical names to url stubs that work with prop65 website. The urls will then be mapped to Wikidata entries with the property that were added via Mix N match. Normally, urls can be tested, but CA Prop 65 website has captcha protection and blocks scrapers.\n",
    "\n",
    "Example conversion:\n",
    "\"OEHHA listing\" --> \"OEHHA url\" | \"Prop 65 listing\" --> \"Prop 65 url\"\n",
    "* \"Amino-alpha-carboline\" --> \"amino-alpha-carboline\" | \"A-alpha-C (2-Amino-9H-pyrido[2,3-b]indole)\" --> \"alpha-c-2-amino-9h-pyrido23-bindole\"\n",
    "* \"Allyl Chloride\" --> \"allyl-chloride\" | not listed\n",
    "* \"alpha-Methylstyrene\" --> \"alpha-methylstyrene\" | \"?-Methyl styrene (alpha-Methylstyrene)\" --> \"methyl-styrene-alpha-methylstyrene\"\n",
    "* \"MeIQx (2-Amino-3,8-dimethylimidazo[4,5-f]quinoxaline)\" --> \"meiqx-2-amino-38-dimethylimidazo45-fquinoxaline\" | \"MeIQx (2-Amino-3,8-dimethylimidazo[4,5-f]quinoxaline)\" --> \"meiqx-2-amino-38-dimethylimidazo45-fquinoxaline\"\n",
    "* \"2-Mercaptobenzothiazole\" --> \"2-mercaptobenzothiazole\" | \"2?Mercaptobenzothiazole\" --> \"2-mercaptobenzothiazole\"\n",
    "* \"Trp-P-1 (Tryptophan-P-1)\" --> \"trp-p-1-tryptophan-p-1\" | \"Trp-P-1 (Tryptophan-P-1)\" --> \"trp-p-1-tryptophan-p-1\"\n",
    "* \"Alcoholic beverages, when associated with alcohol abuse\" --> \"alcoholic-beverages\" | \"Alcoholic beverages, when associated with alcohol abuse\" --> \"alcoholic-beverages\"\n",
    "* \"Aspirin\" --> \"aspirin\" | \"Aspirin (NOTE:  It is especially  important not to use aspirin during the last three months of pregnancy,  unless specifically directed to do so by a physician because it may cause  problems in the unborn child or  complications during delivery.)\" --> \"aspirin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ginger\\anaconda3\\envs\\pywikibot\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "c:\\users\\ginger\\anaconda3\\envs\\pywikibot\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Entry ID           Entry name  \\\n",
      "0  abiraterone-acetate  Abiraterone acetate   \n",
      "2         acetaldehyde         Acetaldehyde   \n",
      "\n",
      "                              Entry description  \n",
      "0  Abiraterone acetate, CAS Number: 154229-18-2  \n",
      "2             Acetaldehyde, CAS Number: 75-07-0  \n"
     ]
    }
   ],
   "source": [
    "## To convert the title to a url stub, lower case it, strip out parenthesis, brackets, and commas, and replace spaces with dashes\n",
    "prop65_chems['url_stub'] = prop65_chems['Title'].str.lower().str.replace(\"[\",\"\").str.replace(\"]\",\"\").str.replace(\",\",\"\").str.replace(\"(\",\"\").str.replace(\")\",\"\").str.strip(\"]\").str.replace(\" \",\"-\")\n",
    "#print(prop65_chems.head())\n",
    "\n",
    "## Check the look of the url stub\n",
    "#print(prop65_chems.loc[prop65_chems['Title']==\"Allyl Chloride\"])\n",
    "#print(prop65_chems.loc[prop65_chems['Title']==\"Trp-P-1 (Tryptophan-P-1)\"])\n",
    "#print(prop65_chems.loc[prop65_chems['Title']==\"MeIQx (2-Amino-3,8-dimethylimidazo[4,5-f]quinoxaline)\"])\n",
    "#print(prop65_chems.head(n=2))\n",
    "\n",
    "#print(prop65_chems.head(n=2))\n",
    "mixnmatch_cat = prop65_chems[['url_stub','Title','CAS Number']]\n",
    "mixnmatch_cat.rename(columns={'url_stub':'Entry ID','Title':'Entry name'}, inplace=True)\n",
    "mixnmatch_cat['Entry description'] = mixnmatch_cat['Entry name'].astype(str).str.cat(mixnmatch_cat['CAS Number'].astype(str),sep=\", CAS Number: \")\n",
    "mixnmatch_cat.drop('CAS Number',axis=1,inplace=True)\n",
    "print(mixnmatch_cat.head(n=2))\n",
    "\n",
    "mixnmatch_cat.to_csv('data/mixnmatch_cat.tsv',sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delisted items\n",
    "\n",
    "After scanning the data, it appears that this table will allow us to easily identify entities which were 100% delisted, but it will require a bit more logic to identify entities that have been delisted for some conditions but not others.\n",
    "\n",
    "Some sample comparisons between the Prop 65 list and the OEHHA list:\n",
    "\n",
    "As seen in Prop 65 list, we can see that BPA was listed as causing female reproductive and developmental toxicity, but it's listing as a developmental toxicant was removed on April 19, 2013.\n",
    "* Bisphenol A (BPA)\tfemale\n",
    "* Bisphenol A (BPA)  Delisted April 19, 2013 developmental\n",
    "\n",
    "In contrast its (Bisphenol A) entry in the OEHHA list is illustrated as follows:\n",
    "* Reproductive Toxicity: Currently listed\n",
    "* Chemical listed under Proposition 65 as causing: Female Reproductive Toxicity\n",
    "* Developmental Toxicity - Date of Listing: 4/11/2013\n",
    "* Developmental Toxicity - Listing Mechanism: AB-NTP-CERHR\n",
    "* Female Reproductive Toxicity - Date of Listing:\t5/11/2015\n",
    "* Female Reproductive Toxicity - Listing Mechanism: SQE\n",
    "\n",
    "As seen above, the delisting as a developmental toxicity item has to be inferred based on it's listing as causing only Female Reproductive Toxicity event though it has entries for dates and mechanism for Developmental toxicity entries.\n",
    "\n",
    "Completely delisted entries are more straightforward as seen in the case of Allyl Chloride:\n",
    "This entity is not even listed in the Prop 65 list. In contrast, in the OEHHA list it appears as:\n",
    "* Cancer: Formerly listed\n",
    "* Cancer - Listing Mechanism: AB-US EPA \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "### Identify completely delisted items\n",
    "delisted_df = prop65_chems.loc[((prop65_chems['Cancer']==\"Formerly listed\") & (prop65_chems['Reproductive Toxicity']==\"None\"))|\n",
    "                               ((prop65_chems['Cancer']==\"None\") & (prop65_chems['Reproductive Toxicity']==\"Formerly listed\"))]\n",
    "delisted_titles = delisted_df['Title'].tolist()\n",
    "#print(delisted_df.head(n=5))\n",
    "print(len(delisted_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items under consideration or considered, but not listed\n",
    "We can pull these, but it's not clear how they should be included in Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considered, not listed:  60 Under consideration:  4\n"
     ]
    }
   ],
   "source": [
    "### Identify items that were considered, but not listed\n",
    "considered_df = prop65_chems.loc[((prop65_chems['Cancer']==\"Considered, but not listed\") & (prop65_chems['Reproductive Toxicity']==\"None\"))|\n",
    "                               ((prop65_chems['Cancer']==\"None\") & (prop65_chems['Reproductive Toxicity']==\"Considered, but not listed\"))]\n",
    "considered_titles = considered_df['Title'].tolist()\n",
    "#print(considered_df.head(n=5))\n",
    "\n",
    "### Identify items that are under consideration\n",
    "considering_df = prop65_chems.loc[((prop65_chems['Cancer']==\"Under consideration\") & (prop65_chems['Reproductive Toxicity']==\"None\"))|\n",
    "                               ((prop65_chems['Cancer']==\"None\") & (prop65_chems['Reproductive Toxicity']==\"Under consideration\"))]\n",
    "considering_titles = considering_df['Title'].tolist()\n",
    "#print(considering_df.head(n=5))\n",
    "print(\"Considered, not listed: \",len(considered_df),\"Under consideration: \", len(considering_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partially delisted items\n",
    "\n",
    "We can filter for these by removing items that were completely delisted, and items that were considered, or under consideration. Next, we'll need to count the number of entries under \"Chemical listed under Proposition 65 as causing\", and checking to see if the same number of columns are empty, or if there are more columns not empty than there are number of entries under \"Chemical listed under Proposition 65 as causing\"\n",
    "\n",
    "Or items which are delisted under either Cancer or Reproductive Toxicity but is NOT empty for the other item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items currently listed under prop 65:  851\n",
      "Items partially delisted for cancer or reproductive toxicity:  2\n"
     ]
    }
   ],
   "source": [
    "### Remove entries which were completely delisted, are under consideration, or considered, and not listed\n",
    "prop_65_listed = prop65_chems.loc[~prop65_chems['Title'].isin(delisted_titles+considered_titles+considering_titles)].copy()\n",
    "print(\"Items currently listed under prop 65: \", len(prop_65_listed))\n",
    "\n",
    "\n",
    "### Identify cancer vs reproductive partially delisted items\n",
    "part_delisted_df = prop_65_listed.loc[((prop_65_listed['Cancer']==\"Formerly listed\") & (prop_65_listed['Reproductive Toxicity']==\"Currently listed\"))|\n",
    "                               ((prop_65_listed['Cancer']==\"Currently listed\") & (prop_65_listed['Reproductive Toxicity']==\"Formerly listed\"))]\n",
    "part_delisted_titles = part_delisted_df['Title'].tolist()\n",
    "#print(part_delisted_df.head(n=5))\n",
    "print(\"Items partially delisted for cancer or reproductive toxicity: \", len(part_delisted_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identify items that were partially delisted for one type of reproductive toxicity or another\n",
    "prop_65_listed['Dev current'] = prop_65_listed['Chemical listed under Proposition 65 as causing'].str.contains(\"Development\")\n",
    "prop_65_listed['Male current'] = prop_65_listed['Chemical listed under Proposition 65 as causing'].str.contains(\"Male\")\n",
    "prop_65_listed['Female current'] = prop_65_listed['Chemical listed under Proposition 65 as causing'].str.contains(\"Female\")\n",
    "\n",
    "#print(prop_65_listed.head(n=2))\n",
    "### These can be identified as items which are not none for date of list/listing mechanism \n",
    "### for a particular type of toxicity, but is listed as \"False\" for the corresponding toxicity\n",
    "part_delisted_dev_df = prop_65_listed.loc[(~prop_65_listed['Title'].isin(part_delisted_titles)) &\n",
    "                                            (((prop_65_listed['Developmental Toxicity - Date of Listing']!=\"None\")|\n",
    "                                             (prop_65_listed['Developmental Toxicity - Listing Mechanism']!=\"None\"))&\n",
    "                                             (prop_65_listed['Dev current']==False))]\n",
    "part_delisted_fem_df = prop_65_listed.loc[(~prop_65_listed['Title'].isin(part_delisted_titles)) &\n",
    "                                            (((prop_65_listed['Female Reproductive Toxicity - Date of Listing']!=\"None\")|\n",
    "                                             (prop_65_listed['Female Reproductive Toxicity - Listing Mechanism']!=\"None\"))&\n",
    "                                             (prop_65_listed['Female current']==False))]\n",
    "part_delisted_male_df = prop_65_listed.loc[(~prop_65_listed['Title'].isin(part_delisted_titles)) &\n",
    "                                            (((prop_65_listed['Male Reproductive Toxicity - Date of Listing']!=\"None\")|\n",
    "                                             (prop_65_listed['Male Reproductive Toxicity - Listing Mechanism']!=\"None\"))&\n",
    "                                             (prop_65_listed['Male current']==False))]   \n",
    "#print(part_delisted_dev_df.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844\n"
     ]
    }
   ],
   "source": [
    "### Identify items that have not been delisted at all\n",
    "part_delisted_dev_titles = part_delisted_dev_df['Title'].tolist()\n",
    "part_delisted_fem_titles = part_delisted_fem_df['Title'].tolist()\n",
    "part_delisted_male_titles = part_delisted_male_df['Title'].tolist()\n",
    "not_delisted = prop_65_listed.loc[(~prop_65_listed['Title'].isin(part_delisted_titles))&\n",
    "                                  (~prop_65_listed['Title'].isin(part_delisted_dev_titles))&\n",
    "                                  (~prop_65_listed['Title'].isin(part_delisted_fem_titles))&\n",
    "                                  (~prop_65_listed['Title'].isin(part_delisted_male_titles))]\n",
    "print(len(not_delisted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Run\n",
    "The initial run should write both the listed and delisted entities. The tables should be stored so that future exports can be compared prior runs to minimize the actual number of writes needed to keep the data up-to-date. The normalization of entities will depend on assignments by Mix N Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to handle the listing and delisting dates via the references\n",
    "\n",
    "* Chemical causes cancer --> Instance (P31) of carcinogen\n",
    "* Chemical causes developmental toxicity --> Instance (P31) of developmental toxicant\n",
    "* Chemical causes reproductive toxicity --> Instance (P31) of reproductive toxicant\n",
    "* Statement date --> retrieved (P813) : access date \n",
    "* Date listed --> start time (P580) : from date \n",
    "* Date delisted --> end time (P582) : end date \n",
    "* Delisted --> reason for deprecation (P2241) in conjunction with disqualification (Q1229261)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run sparql query to pull all entities with Prop 65 ID (Read Only Run)\n",
    "prop65_urls = prop65_chems['url_stub'].tolist()\n",
    "i=0\n",
    "wdmap = []\n",
    "wdmapfail = []\n",
    "for i in tqdm(range(len(prop65_urls))):\n",
    "    prop65_id = prop65_urls[i]\n",
    "    try:\n",
    "        sparqlQuery = \"SELECT * WHERE {?topic wdt:PXXX \\\"\"+prop65_id+\"\\\"}\"\n",
    "        result = wdi_core.WDItemEngine.execute_sparql_query(sparqlQuery)\n",
    "        query_qid = result[\"results\"][\"bindings\"][0][\"topic\"][\"value\"].replace(\"http://www.wikidata.org/entity/\", \"\")\n",
    "        wdmap.append({'url_stub':prop65_id,'WDID':query_qid})\n",
    "    except:\n",
    "        wdmapfail.append(prop65_id)\n",
    "    i=i+1\n",
    "\n",
    "## Inspect the results for mapping or coverage issues\n",
    "wdid_prop65_df = pd.DataFrame(wdmap)\n",
    "print(\"resulting mapping table has: \",len(wdid_prop65_df),\" rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform left merge for currently listed and partially delisted items\n",
    "prop_65_mapped = prop_65_listed.merge(wdid_prop65_df, on='url_stub', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial run for current listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unit test\n",
    "\n",
    "\n",
    "carcinogen_qid = 'Q187661'\n",
    "devtox_qid = 'Q72941151'\n",
    "femreptox_qid = 'Q55427776'\n",
    "malereptox_qid = 'Q55427774'\n",
    "\n",
    "prop_65_url = 'https://oehha.ca.gov/proposition-65/chemicals/abiraterone-acetate'\n",
    "prop_65_id = 'abiraterone-acetate'\n",
    "prop_65_qid = 'Q4115189' #'Q27888393'\n",
    "reference = create_reference(ghr_url)\n",
    "list_prop = \"P31\" \n",
    "start_date = '04/08/2016'\n",
    "delist_date = '4/19/2013'\n",
    "\n",
    "list_qualifier = wdi_core.WDTime(datetime.strptime(start_date,'%m/%d/%Y').strftime(\"+%Y-%m-%dT00:00:00Z\"), prop_nr='P580', is_qualifier=True)\n",
    "dev_statement = [wdi_core.WDString(value=devtox_qid, prop_nr=list_prop, \n",
    "                               qualifiers=[list_qualifier],\n",
    "                               references=[copy.deepcopy(reference)])]\n",
    "\n",
    "item = wdi_core.WDItemEngine(wd_item_id=prop_65_qid, data=dev_statement, append_value=prop_65_url,\n",
    "                           global_ref_mode='CUSTOM', ref_handler=update_retrieved_if_new_multiple_refs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial run for completely delisted items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial run for partially delisted items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export results for future investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scheduled Runs\n",
    "The maintenance runs should parse the data similar to the previous runs and compare the results to look for new entries to add and new delistings to deprecate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "## Unit test --  write a statement\n",
    "disease_qid = 'Q4115189' #'Q2703116'\n",
    "ghr_url = 'https://ghr.nlm.nih.gov/condition/15q11-q13-duplication-syndrome'\n",
    "ghr_id = '15q11-q13-duplication-syndrome'\n",
    "reference = create_reference(ghr_url)\n",
    "url_prop = \"P7464\" \n",
    "start_date = '4/11/2013'\n",
    "delist_date = '4/19/2013'\n",
    "\n",
    "\n",
    "list_qualifier = wdi_core.WDTime(datetime.strptime(start_date,'%m/%d/%Y').strftime(\"+%Y-%m-%dT00:00:00Z\"), prop_nr='P580', is_qualifier=True)\n",
    "delist_qualifier = wdi_core.WDTime(datetime.strptime(delist_date,'%m/%d/%Y').strftime(\"+%Y-%m-%dT00:00:00Z\"), prop_nr='P582', is_qualifier=True)\n",
    "delist_reason = wdi_core.WDItemID('Q56478729', prop_nr='P2241', is_qualifier=True)\n",
    "\n",
    "statement = [wdi_core.WDString(value=ghr_id, prop_nr=url_prop, rank='deprecated', \n",
    "                               qualifiers=[list_qualifier,delist_qualifier,delist_reason],\n",
    "                               references=[copy.deepcopy(reference)])]\n",
    "item = wdi_core.WDItemEngine(wd_item_id=disease_qid, data=statement, append_value=url_prop,\n",
    "                           global_ref_mode='CUSTOM', ref_handler=update_retrieved_if_new_multiple_refs)\n",
    "item.write(login)\n",
    "print(ghr_id, disease_qid, ghr_url)\n",
    "  \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How deprecations are handled in Gene Bot (which uses WDI):\n",
    "\"\"\"\n",
    "def remove_deprecated_statements(qid, frc, releases, last_updated, props, login):\n",
    "\n",
    "#    :param qid: qid of item\n",
    "#    :param frc: a fastrun container\n",
    "#    :param releases: list of releases to remove (a statement that has a reference that is stated in one of these\n",
    "#            releases will be removed)\n",
    "#    :param last_updated: looks like {'Q20641742': datetime.date(2017,5,6)}. a statement that has a reference that is\n",
    "#            stated in Q20641742 (entrez) and was retrieved more than DAYS before 2017-5-6 will be removed\n",
    "#    :param props: look at these props\n",
    "#    :param login:\n",
    "#    :return:\n",
    "    for prop in props:\n",
    "        frc.write_required([wdi_core.WDString(\"fake value\", prop)])\n",
    "    orig_statements = frc.reconstruct_statements(qid)\n",
    "    releases = set(int(r[1:]) for r in releases)\n",
    "\n",
    "    s_dep = []\n",
    "    for s in orig_statements:\n",
    "        if any(any(x.get_prop_nr() == 'P248' and x.get_value() in releases for x in r) for r in s.get_references()):\n",
    "            setattr(s, 'remove', '')\n",
    "            s_dep.append(s)\n",
    "        else:\n",
    "            for r in s.get_references():\n",
    "                dbs = [x.get_value() for x in r if x.get_value() in last_updated]\n",
    "                if dbs:\n",
    "                    db = dbs[0]\n",
    "                    if any(x.get_prop_nr() == 'P813' and last_updated[db] - x.get_value() > DAYS for x in r):\n",
    "                        setattr(s, 'remove', '')\n",
    "                        s_dep.append(s)\n",
    "    if s_dep:\n",
    "        print(\"-----\")\n",
    "        print(qid)\n",
    "        print(len(s_dep))\n",
    "        print([(x.get_prop_nr(), x.value) for x in s_dep])\n",
    "        print([(x.get_references()[0]) for x in s_dep])\n",
    "        wd_item = wdi_core.WDItemEngine(wd_item_id=qid, data=s_dep, fast_run=False)\n",
    "        wdi_helpers.try_write(wd_item, '', '', login, edit_summary=\"remove deprecated statements\")\n",
    "\"\"\"\n",
    "\n",
    "### How to get rank using WDI\n",
    "\"\"\"\n",
    "item = wdi_core.WDItemEngine(wd_item_id=qid)\n",
    "new_ss = []\n",
    "for s in item.statements:  # type: wdi_core.WDBaseDataType\n",
    "    if s.get_rank() != \"normal\":\n",
    "        continue\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "### How to handled deprecations using pywikibot\n",
    "\"\"\"\n",
    "https://doc.wikimedia.org/pywikibot/master/_modules/pywikibot/page.html#Claim.changeRank\n",
    "\"\"\"\n",
    "\n",
    "### WDI rank handling\n",
    "\"\"\"\n",
    "type rank: A string of one of three allowed values: 'normal', 'deprecated', 'preferred'\n",
    "\n",
    "\n",
    "    def get_rank(self):\n",
    "        if self.is_qualifier or self.is_reference:\n",
    "            return ''\n",
    "        else:\n",
    "            return self.rank\n",
    "\n",
    "    def set_rank(self, rank):\n",
    "        if self.is_qualifier or self.is_reference:\n",
    "            raise ValueError('References or qualifiers do not have ranks')\n",
    "\n",
    "        valid_ranks = ['normal', 'deprecated', 'preferred']\n",
    "\n",
    "        if rank not in valid_ranks:\n",
    "            raise ValueError('{} not a valid rank'.format(rank))\n",
    "\n",
    "        self.rank = rank\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one(taxid, genbank_id):\n",
    "    # get the QID\n",
    "    taxid = str(taxid)\n",
    "    if taxid not in tax_qid_map:\n",
    "        msg = wdi_helpers.format_msg(genbank_id, PROPS['GenBank Assembly accession'], \"\",\n",
    "                               \"organism with taxid {} not found or skipped\".format(taxid))\n",
    "        wdi_core.WDItemEngine.log(\"WARNING\", msg)\n",
    "        return None\n",
    "    qid = tax_qid_map[taxid]\n",
    "    reference = create_reference(genbank_id)\n",
    "    genbank_statement = wdi_core.WDExternalID(genbank_id, PROPS['GenBank Assembly accession'], references=[reference])\n",
    "    \n",
    "    # create the item object, specifying the qid\n",
    "    item = wdi_core.WDItemEngine(data=[genbank_statement], wd_item_id=qid, fast_run=True, \n",
    "                                 fast_run_base_filter={PROPS['GenBank Assembly accession']: ''})\n",
    "\n",
    "    wdi_helpers.try_write(item, record_id=genbank_id, record_prop=PROPS['GenBank Assembly accession'],\n",
    "                          login=login, edit_summary=\"update GenBank Assembly accession\")\n",
    "    \n",
    "\n",
    "def run_one(taxid, genbank_id):\n",
    "    # create a statement for the ncbi tax id\n",
    "    ncbi_statement = wdi_core.WDExternalID(str(taxid), PROPS['NCBI Taxonomy ID'])\n",
    "    # we are going to retrieve the item to be modified based on the NCBI Taxonomy ID, which should already exist on all organisms.\n",
    "    try:\n",
    "        item = wdi_core.WDItemEngine(data=[ncbi_statement], domain=\"organism\", search_only=True, item_name=\"organism\")\n",
    "    except wdi_core.ManualInterventionReqException as e:\n",
    "        # if there are more than one items with this ncbi tax id, this will throw an error!\n",
    "        # instead, catch it and log the error\n",
    "        msg = wdi_helpers.format_msg(genbank_id, PROPS['GenBank Assembly accession'], \"\", str(e), type(e))\n",
    "        wdi_core.WDItemEngine.log(\"ERROR\", msg)\n",
    "        return\n",
    "    \n",
    "    if item.wd_item_id:\n",
    "        # if the item exists, create the genbank statement\n",
    "        reference = create_reference(genbank_id)\n",
    "        genbank_statement = wdi_core.WDExternalID(genbank_id, PROPS['GenBank Assembly accession'], references=[reference])\n",
    "        # create the item object, specifying the qid\n",
    "        item = wdi_core.WDItemEngine(data=[genbank_statement], wd_item_id=item.wd_item_id)\n",
    "        # use this helper method to perform the write. It automatically writes to a log file and captures errors\n",
    "        # wdi also has an automatic backoff and retry functionality\n",
    "        wdi_helpers.try_write(item, record_id=genbank_id, record_prop=PROPS['GenBank Assembly accession'],\n",
    "                              login=login, edit_summary=\"update GenBank Assembly accession\")\n",
    "    else:\n",
    "        # if the item doesn't exist, log it and skip\n",
    "        msg = wdi_helpers.format_msg(genbank_id, PROPS['GenBank Assembly accession'], \"\",\n",
    "                               \"No organism found with taxid {}\".format(taxid))\n",
    "        wdi_core.WDItemEngine.log(\"WARNING\", msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
