{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GARD data loading with WDI\n",
    "\n",
    "Example of how to use wikidata integrator to add synonyms from GARD. GARD data has already PARTIALLY been loaded into Wikidata via Mix N Match. It is important not to overwrite Mix N Match results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all necessary modules and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidataintegrator import wdi_core, wdi_login\n",
    "from wikidataintegrator.ref_handlers import update_retrieved_if_new_multiple_refs\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import requests\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import ipywidgets \n",
    "import widgetsnbextension\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### login section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieving API credentials\n"
     ]
    }
   ],
   "source": [
    "print(\"retrieving API credentials\")\n",
    "import wdi_user_config\n",
    "api_dict = wdi_user_config.get_gard_credentials()\n",
    "header_info = {api_dict['name']: api_dict['value']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in...\n",
      "https://www.wikidata.org/w/api.php\n",
      "Successfully logged in as Gtsulab\n"
     ]
    }
   ],
   "source": [
    "print(\"Logging in...\")\n",
    "import wdi_user_config ## Credentials stored in a wdi_user_config file\n",
    "login_dict = wdi_user_config.get_credentials()\n",
    "login = wdi_login.WDLogin(login_dict['WDUSER'], login_dict['WDPASS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull all disease entities from GARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "gard_results = requests.get('https://api.rarediseases.info.nih.gov/api/diseases',\n",
    "                           headers=header_info)\n",
    "print(gard_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   diseaseId                        diseaseName  hasGardWebPage  \\\n",
      "0      13018  10q22.3q23 microdeletion syndrome            True   \n",
      "1       5658     11-beta-hydroxylase deficiency            True   \n",
      "\n",
      "                                         identifiers  isRare  \\\n",
      "0                                                 []    True   \n",
      "1  [{'identifierType': 'OMIM', 'identifierId': '2...    True   \n",
      "\n",
      "                                            synonyms  \\\n",
      "0  [Del(10)(q22.3q23.3), Deletion 10q22.3q23.3, M...   \n",
      "1  [Congenital adrenal hyperplasia due to 11-beta...   \n",
      "\n",
      "                                          websiteUrl  \n",
      "0  https://rarediseases.info.nih.gov/diseases/130...  \n",
      "1  https://rarediseases.info.nih.gov/diseases/565...  \n"
     ]
    }
   ],
   "source": [
    "gard_df = pd.read_json(gard_results.text)\n",
    "print(gard_df.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we can easily pull the synonyms from this dataframe and upload them to Wikidata, we only have permission to upload data specifically generated by GARD. Hence we will need to visit each disease's page in GARD to check the source of the synonyms.  While we're at it, we can also pull alternate identifiers (which will NOT be loaded to Wikidata), but can be used for mapping.  Since the Mix N Match community has already done a lot of GARD ID mapping, we will only need these alternative identifiers for items which don't yet have GARD IDs mapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The resulting json file has a key \"mainPropery\" which is where our desired data is stored\n",
    "## Since it looks like a misspelling, we'll store that key as a variable so that it'll be easy to\n",
    "## change in the future if the key is changed in the future\n",
    "key_of_interest = \"mainPropery\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                name         source  diseaseID\n",
      "0  Congenital adrenal hyperplasia due to 11-beta-...           GARD       5658\n",
      "1                             Adrenal hyperplasia IV           GARD       5658\n",
      "2                              Adrenal hyperplasia 4           GARD       5658\n",
      "3             Steroid 11-beta-hydroxylase deficiency           GARD       5658\n",
      "4              Adrenal hyperplasia hypertensive form           GARD       5658\n",
      "5                               P450c11b1 deficiency           GARD       5658\n",
      "6          CAH due to 11-beta-hydroxylase deficiency  OrphaData.Org       5658\n",
      "7                                 CYP11B1 deficiency  OrphaData.Org       5658\n",
      "  identifierId identifierType\n",
      "0       202010           OMIM\n",
      "1        90795       ORPHANET\n",
      "2     C0268292           UMLS\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Unit test: Request and parse a sample page\n",
    "i=1\n",
    "fail_list = []\n",
    "\n",
    "sample_result = requests.get('https://api.rarediseases.info.nih.gov/api/diseases/'+str(gard_df.iloc[i]['diseaseId']),\n",
    "                           headers=header_info)\n",
    "\n",
    "json_result = sample_result.json()\n",
    "data_of_interest = json_result.get(key_of_interest)\n",
    "\n",
    "## Check if there are synonyms that don't have a source (ie- are by GARD)\n",
    "sourced_syn = data_of_interest.get('synonyms-with-source')\n",
    "identifier_results = data_of_interest.get('identifiers')\n",
    "\n",
    "tmpdict = pd.DataFrame(sourced_syn).fillna(\"GARD\")\n",
    "tmpdict['diseaseId'] = gard_df.iloc[i]['diseaseId']\n",
    "print(tmpdict)\n",
    "\n",
    "## Check if there are identifiers that can be used for xrefs\n",
    "identifier_dict = pd.DataFrame(identifier_results).fillna(\"None\")\n",
    "print(identifier_dict)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01c5a07d9fd4347a4b3300e0f9fc9ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6180), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identifiers found:  10542\n",
      "Synonyms found:  15788\n",
      "Requests failed:  0\n",
      "GARD IDs with no synonyms:  1234\n",
      "GARD IDs with no xrefs:  916\n"
     ]
    }
   ],
   "source": [
    "gard_id_list = gard_df['diseaseId'].unique().tolist()\n",
    "#gard_id_list = [13018,5658,10095] ## Iteration test\n",
    "fail_list = []\n",
    "no_syns = []\n",
    "no_idens = []\n",
    "identifier_df = pd.DataFrame(columns=['diseaseId','identifierId','identifierType'])\n",
    "synonyms_df = pd.DataFrame(columns=['diseaseId','name','source'])\n",
    "\n",
    "for i in tqdm(range(len(gard_id_list))):\n",
    "    try:\n",
    "        sample_result = requests.get('https://api.rarediseases.info.nih.gov/api/diseases/'+str(gard_df.iloc[i]['diseaseId']),\n",
    "                                   headers=header_info)\n",
    "        json_result = sample_result.json()\n",
    "        data_of_interest = json_result.get(key_of_interest)\n",
    "        ## Check if there are synonyms that don't have a source (ie- are by GARD)\n",
    "        sourced_syn = data_of_interest.get('synonyms-with-source')\n",
    "        tmpdict = pd.DataFrame(sourced_syn).fillna(\"GARD\")\n",
    "        tmpdict['diseaseId'] = gard_df.iloc[i]['diseaseId']\n",
    "        if len(tmpdict) == 0:\n",
    "            no_syns.append(gard_df.iloc[i]['diseaseId'])\n",
    "        else:\n",
    "            synonyms_df = pd.concat((synonyms_df,tmpdict),ignore_index=True)\n",
    "\n",
    "        ## Check if there are identifiers that can be used for xrefs\n",
    "        identifier_results = data_of_interest.get('identifiers')\n",
    "        identifier_dict = pd.DataFrame(identifier_results).fillna(\"None\")\n",
    "        identifier_dict['diseaseId'] = gard_df.iloc[i]['diseaseId']\n",
    "        if len(identifier_dict) == 0:\n",
    "            no_idens.append(gard_df.iloc[i]['diseaseId'])\n",
    "        else:\n",
    "            identifier_df = pd.concat((identifier_df,identifier_dict),ignore_index=True)\n",
    "    \n",
    "    except:\n",
    "        fail_list.append(gard_df.iloc[i]['diseaseId'])\n",
    "\n",
    "print(\"Identifiers found: \", len(identifier_df))\n",
    "print(\"Synonyms found: \", len(synonyms_df))\n",
    "print(\"Requests failed: \",len(fail_list))\n",
    "print(\"GARD IDs with no synonyms: \", len(no_syns))\n",
    "print(\"GARD IDs with no xrefs: \", len(no_idens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export results to avoid having to hit the API again\n",
    "identifier_df.to_csv('data/identifier_df.tsv',sep='\\t',header=True)\n",
    "synonyms_df.to_csv('data/synonyms_df.tsv',sep='\\t',header=True)\n",
    "\n",
    "with open('data/no_syns.txt','w') as outwrite:\n",
    "    for eachentry in no_syns:\n",
    "        outwrite.write(str(eachentry)+'\\n')\n",
    "\n",
    "with open('data/no_idens.txt','w') as idenwrite:\n",
    "    for eachiden in no_idens:\n",
    "        idenwrite.write(str(eachiden)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  diseaseID identifierID identifierId identifierType\n",
      "0      5658          NaN       202010           OMIM\n",
      "1      5658          NaN        90795       ORPHANET\n",
      "2      5658          NaN     C0268292           UMLS\n"
     ]
    }
   ],
   "source": [
    "print(identifier_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import any data that was exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier_df = read_csv('data/identifier_df.tsv',delimiter='\\t',header=0,index_col=0)\n",
    "synonyms_df = read_csv('data/synonyms_df.tsv',delimiter='\\t',header=0,index_col=0, encoding='latin-1')\n",
    "\n",
    "no_syns=[]\n",
    "with open('data/no_syns.txt','r') as syn_read:\n",
    "    for line in syn_read:\n",
    "        no_syns.append(line.strip('\\n'))\n",
    "no_idens=[]\n",
    "with open('data/no_idens.txt','r') as iden_read:\n",
    "    for line in no_idens:\n",
    "        no_idens.append(line.strip('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull all WD entities with GARD IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all QIDs with GARD IDs\n",
    "\n",
    "sparqlQuery = \"SELECT * WHERE {?item wdt:P4317 ?GARD}\"\n",
    "result = wdi_core.WDItemEngine.execute_sparql_query(sparqlQuery)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b299b137904b2592dfd2e4e3328484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4198), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        WDID diseaseId\n",
      "0   Q5514398         1\n",
      "1  Q18553682     10346\n",
      "2  Q32038811     10539\n"
     ]
    }
   ],
   "source": [
    "gard_in_wd_list = []\n",
    "\n",
    "for i in tqdm(range(len(result[\"results\"][\"bindings\"]))):\n",
    "    gard_id = result[\"results\"][\"bindings\"][i][\"GARD\"][\"value\"]\n",
    "    wdid = result[\"results\"][\"bindings\"][i][\"item\"][\"value\"].replace(\"http://www.wikidata.org/entity/\", \"\")\n",
    "    gard_in_wd_list.append({'WDID':wdid,'diseaseId':gard_id})\n",
    "\n",
    "gard_in_wd = pd.DataFrame(gard_in_wd_list)\n",
    "print(gard_in_wd.head(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify GARD diseases not yet in Wikidata\n",
    "Currently, there is no bot to add GARD ID to Wikidata entities, so the GARD IDs in Wikidata were added via Mix N Match. Identify the GARD diseases not yet in Wikidata, and determine if they can be mapped using one of the other identifiers available via GARD (eg- Orphanet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "1880\n",
      "   diseaseId identifierId identifierType\n",
      "0       5658       202010           OMIM\n",
      "1       5658        90795       ORPHANET\n",
      "['OMIM', 'ORPHANET', 'UMLS', 'SNOMED CT', 'ICD 10', 'NCI Thesaurus', 'ICD 10-CM', 'MeSH']\n"
     ]
    }
   ],
   "source": [
    "gard_in_wd_id_list = gard_in_wd['diseaseId'].unique().tolist()\n",
    "\n",
    "gard_not_in_wd = identifier_df.loc[~identifier_df['diseaseId'].isin(gard_in_wd_id_list)]\n",
    "print(len(gard_not_in_wd))\n",
    "print(len(gard_not_in_wd['diseaseId'].unique().tolist()))\n",
    "print(gard_not_in_wd.head(n=2))\n",
    "property_list = gard_not_in_wd['identifierType'].unique().tolist()\n",
    "print(property_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull disease lists based on identifiers so that multiple merges can be used to determine best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P492\n"
     ]
    }
   ],
   "source": [
    "prop_id_dict = {'OMIM':'P492', 'ORPHANET':'P1550', 'UMLS':'P2892',\n",
    "                'SNOMED CT':'P5806', 'ICD 10':'P494', 'NCI Thesaurus':'P1748',\n",
    "                'ICD 10-CM':'P4229', 'MeSH':'P486'}\n",
    "print(prop_id_dict['OMIM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334d14016978446088b9a237dc997490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-585eb1860589>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwdi_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWDItemEngine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_sparql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparqlQuery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"results\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bindings\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mid_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"results\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bindings\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'identifierId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mwdid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"results\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bindings\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"item\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://www.wikidata.org/entity/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0midentifier_megalist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'WDID'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mwdid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'identifierId'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mid_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'identifierType'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mproperty_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0meachidtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not dict"
     ]
    }
   ],
   "source": [
    "sparql_start = 'SELECT * WHERE {?item wdt:'\n",
    "sparql_end = '}'\n",
    "\n",
    "identifier_megalist=[]\n",
    "\n",
    "for eachidtype in property_list:\n",
    "    sparqlQuery = sparql_start + prop_id_dict[eachidtype] + ' ?identifierId'+sparql_end\n",
    "    result = wdi_core.WDItemEngine.execute_sparql_query(sparqlQuery)\n",
    "    for i in tqdm(range(len(result[\"results\"][\"bindings\"]))):\n",
    "        id_id = result[\"results\"][\"bindings\"][i]['identifierId'][\"value\"]\n",
    "        wdid = result[\"results\"][\"bindings\"][i][\"item\"][\"value\"].replace(\"http://www.wikidata.org/entity/\", \"\")\n",
    "        identifier_megalist.append({'WDID':wdid,'identifierId':id_id, 'identifierType':eachidtype})\n",
    "    print(len(identifier_megalist))\n",
    "    time.sleep(2)\n",
    "        \n",
    "identifier_megadf = pd.DataFrame(identifier_megalist)\n",
    "identifier_megadf.to_csv('data/identifier_megadf.tsv',sep='\\t',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease IDs for which identifiers couldn't be used to find a QID:  276\n",
      "   diseaseId       WDID  identifier_count                    diseaseName  \\\n",
      "0          1   Q5514398                 3               GRACILE syndrome   \n",
      "1         16  Q55998700                 2  Oculomotor apraxia Cogan type   \n",
      "\n",
      "   hasGardWebPage                                        identifiers  isRare  \\\n",
      "0            True  [{'identifierType': 'OMIM', 'identifierId': '6...    True   \n",
      "1            True  [{'identifierType': 'ORPHANET', 'identifierId'...    True   \n",
      "\n",
      "                                            synonyms  \\\n",
      "0  [FLNMS, Finnish lactic acidosis with hepatic h...   \n",
      "1  [Congenital oculomotor apraxia, Cogan's syndro...   \n",
      "\n",
      "                                          websiteUrl  \n",
      "0  https://rarediseases.info.nih.gov/diseases/1/g...  \n",
      "1  https://rarediseases.info.nih.gov/diseases/16/...  \n"
     ]
    }
   ],
   "source": [
    "## For each Gard Disease Entry, check for multiple mappings to the same WDID\n",
    "missing_gard_merge = gard_not_in_wd.merge(identifier_megadf,on=(['identifierId', 'identifierType']), how=\"inner\")\n",
    "still_missing = gard_not_in_wd.loc[~gard_not_in_wd['diseaseId'].isin(missing_gard_merge['diseaseId'].unique().tolist())]\n",
    "print(\"Disease IDs for which identifiers couldn't be used to find a QID: \",len(still_missing))\n",
    "\n",
    "## Determine the number of identifiers that support a merge\n",
    "potential_gard = missing_gard_merge.groupby(['diseaseId','WDID']).size().reset_index(name='identifier_count')\n",
    "mapping_check1 = gard_ids_to_add.groupby('diseaseId').size().reset_index(name='qid_count')\n",
    "one_to_many = mapping_check1.loc[mapping_check1['qid_count']>1]\n",
    "#print(len(one_to_many))\n",
    "mapping_check2 = gard_ids_to_add.groupby('WDID').size().reset_index(name='gardid_count')\n",
    "many_to_one = mapping_check2.loc[mapping_check2['gardid_count']>1]\n",
    "#print(len(many_to_one))\n",
    "gard_mapping_issue_ids = one_to_many['diseaseId'].unique().tolist() + many_to_one['WDID'].unique().tolist()\n",
    "\n",
    "gard_to_add = potential_gard.loc[~potential_gard['diseaseId'].isin(gard_mapping_issue_ids) & \n",
    "                                     ~potential_gard['WDID'].isin(gard_mapping_issue_ids) &\n",
    "                                     ~potential_gard['diseaseId'].isin(still_missing)]\n",
    "\n",
    "gard_to_add_full = gard_to_add.merge(gard_df,on='diseaseId',how=\"left\")\n",
    "\n",
    "gard_to_auto_add = gard_to_add_full.loc[gard_to_add_full['identifier_count']>1]\n",
    "gard_to_suggest = gard_to_add_full.loc[gard_to_add_full['identifier_count']==1]\n",
    "print(gard_to_auto_add.head(n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the appropriate Wikidata statements\n",
    "After removing items which have issues with no alternative identifier by which the GARD entry can be mapped, gard entries that map to multiple Wikidata entities, and multiple gard entries that map to a single wikidata entity based entirely on the other identifiers for that entry provided by GARD, we're left with entries we can add and suggest. Entries which map to a single WDID based on MULTIPLE Identifier mappings can be scripted. Entities which map to a single WDID based on a single Identifier, would probably be best sent to Mix N Match to avoid complaints further down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GARD rare disease ID P4317\n",
    "\n",
    "from datetime import datetime\n",
    "import copy\n",
    "def create_reference(gard_url):\n",
    "    refStatedIn = wdi_core.WDItemID(value=\"Q47517289\", prop_nr=\"P248\", is_reference=True)\n",
    "    timeStringNow = datetime.now().strftime(\"+%Y-%m-%dT00:00:00Z\")\n",
    "    refRetrieved = wdi_core.WDTime(timeStringNow, prop_nr=\"P813\", is_reference=True)\n",
    "    refURL = wdi_core.WDUrl(value=gard_url, prop_nr=\"P854\", is_reference=True)\n",
    "\n",
    "    return [refStatedIn, refRetrieved, refURL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Q55998700 https://rarediseases.info.nih.gov/diseases/16/oculomotor-apraxia-cogan-type\n"
     ]
    }
   ],
   "source": [
    "## Unit test --  write a statement\n",
    "gard_qid = gard_to_auto_add.iloc[1]['WDID']\n",
    "gard_url = gard_to_auto_add.iloc[1]['websiteUrl']\n",
    "gard_id = str(gard_to_auto_add.iloc[1]['diseaseId'])\n",
    "reference = create_reference(gard_url)\n",
    "gard_prop = \"P4317\" \n",
    "statement = [wdi_core.WDString(value=gard_id, prop_nr=gard_prop, references=[copy.deepcopy(reference)])]\n",
    "item = wdi_core.WDItemEngine(wd_item_id=gard_qid, data=statement, append_value=gard_prop,\n",
    "                           global_ref_mode='CUSTOM', ref_handler=update_retrieved_if_new_multiple_refs)\n",
    "item.write(login)\n",
    "edit_id = item.lastrevid\n",
    "print(gard_id, gard_qid, gard_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121bac63a9a648a6b0bb15711f5a9024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Q5514398 https://rarediseases.info.nih.gov/diseases/1/gracile-syndrome\n",
      "16 Q55998700 https://rarediseases.info.nih.gov/diseases/16/oculomotor-apraxia-cogan-type\n",
      "79 Q2964433 https://rarediseases.info.nih.gov/diseases/79/jansen-type-metaphyseal-chondrodysplasia\n",
      "92 Q4352925 https://rarediseases.info.nih.gov/diseases/92/meleda-disease\n",
      "143 Q55780845 https://rarediseases.info.nih.gov/diseases/143/hairy-elbows\n",
      "157 Q55781934 https://rarediseases.info.nih.gov/diseases/157/santos-mateus-leal-syndrome\n",
      "172 Q55786312 https://rarediseases.info.nih.gov/diseases/172/macrocephaly-short-stature-paraplegia-syndrome\n",
      "215 Q55999592 https://rarediseases.info.nih.gov/diseases/215/familial-caudal-dysgenesis\n",
      "217 Q55782090 https://rarediseases.info.nih.gov/diseases/217/roy-maroteaux-kremp-syndrome\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Test write with 10 items completed successfully\n",
    "\n",
    "gard_map_revision_list = []\n",
    "\n",
    "i=0\n",
    "for i in tqdm(range(len(gard_to_auto_add))):\n",
    "    gard_qid = gard_to_auto_add.iloc[i]['WDID']\n",
    "    gard_url = gard_to_auto_add.iloc[i]['websiteUrl']\n",
    "    gard_id = str(gard_to_auto_add.iloc[i]['diseaseId'])\n",
    "    reference = create_reference(gard_url)\n",
    "    gard_prop = \"P4317\" \n",
    "    statement = [wdi_core.WDString(value=gard_id, prop_nr=gard_prop, references=[copy.deepcopy(reference)])]\n",
    "    item = wdi_core.WDItemEngine(wd_item_id=gard_qid, data=statement, append_value=gard_prop,\n",
    "                               global_ref_mode='CUSTOM', ref_handler=update_retrieved_if_new_multiple_refs)\n",
    "    item.write(login,edit_summary='added GARD ID')\n",
    "    gard_map_revision_list.append(item.lastrevid)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the revision list \n",
    "with open('data/mapping_revisions.txt','w') as outwritelog:\n",
    "    for eachrevid in gard_map_revision_list:\n",
    "        outwritelog.write(str(eachrevid)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify synonyms in need of inclusion\n",
    "Pull all the entities mapped via GARD and their corresponding English Aliases. Determine if a synonym is missing from the Alias list and if so, include it.\n",
    "\n",
    "#### Pull all labels and aliases from WD entities with GARD IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q424242'}, 'alias': {'xml:lang': 'en', 'type': 'literal', 'value': 'ADEM'}, 'GARD': {'type': 'literal', 'value': '8639'}, 'itemLabel': {'xml:lang': 'en', 'type': 'literal', 'value': 'acute disseminated encephalomyelitis'}}\n"
     ]
    }
   ],
   "source": [
    "## pull aliases for all entries with GARD IDs\n",
    "sparqlQuery = 'SELECT ?item ?itemLabel ?GARD ?alias WHERE {?item wdt:P4317 ?GARD. OPTIONAL {?item skos:altLabel ?alias FILTER (LANG (?alias) = \"en\").} SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}'\n",
    "result = wdi_core.WDItemEngine.execute_sparql_query(sparqlQuery)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbfcdaa033a433083921561087b2467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21255), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      WDID                        alias  diseaseId  \\\n",
      "0  Q424242                         ADEM       8639   \n",
      "1  Q424242  postinfectious encephalitis       8639   \n",
      "2  Q424242   Postinfective encephalitis       8639   \n",
      "\n",
      "                                  label  \n",
      "0  acute disseminated encephalomyelitis  \n",
      "1  acute disseminated encephalomyelitis  \n",
      "2  acute disseminated encephalomyelitis  \n"
     ]
    }
   ],
   "source": [
    "## Format the results from the Wikidata query into Pandas DF for easier manipulation\n",
    "\n",
    "gard_alias_in_wd_list = []\n",
    "\n",
    "for i in tqdm(range(len(result[\"results\"][\"bindings\"]))):\n",
    "    gard_id = result[\"results\"][\"bindings\"][i][\"GARD\"][\"value\"]\n",
    "    wdid = result[\"results\"][\"bindings\"][i][\"item\"][\"value\"].replace(\"http://www.wikidata.org/entity/\", \"\")\n",
    "    label = result[\"results\"][\"bindings\"][i][\"itemLabel\"][\"value\"]\n",
    "    try:\n",
    "        alias = result[\"results\"][\"bindings\"][i][\"alias\"][\"value\"]\n",
    "    except:\n",
    "        alias = \"No alias\"\n",
    "    gard_alias_in_wd_list.append({'WDID':wdid,'diseaseId':int(gard_id),'label':label,'alias':alias})\n",
    "    ## Note that Wikidata stores the GARD IDs at strings, while GARD stores as int. Convert to ensure matchability\n",
    "\n",
    "gard_alias_in_wd = pd.DataFrame(gard_alias_in_wd_list)\n",
    "print(gard_alias_in_wd.head(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare GARD synonyms with Wikidata aliases and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    diseaseId                              name source       WDID  \\\n",
      "0       10525  Chromosome 15q11.2 microdeletion   GARD  Q21154057   \n",
      "4       10525       Chromosome 15q11.2 deletion   GARD  Q21154057   \n",
      "8       10831                Partial trisomy 1q   GARD  Q55786662   \n",
      "22      10130         Deletion 22q13.3 syndrome   GARD   Q1926345   \n",
      "\n",
      "                                   alias  \\\n",
      "0         15q11.2 microdeletion syndrome   \n",
      "4         15q11.2 microdeletion syndrome   \n",
      "8   Partial duplication of chromosome 1q   \n",
      "22                        22q13 deletion   \n",
      "\n",
      "                                                label  label_match?  \\\n",
      "0                chromosome 15q11.2 deletion syndrome         False   \n",
      "4                chromosome 15q11.2 deletion syndrome         False   \n",
      "8   partial duplication of the long arm of chromos...         False   \n",
      "22                            22q13 deletion syndrome         False   \n",
      "\n",
      "    alias_match?  \n",
      "0          False  \n",
      "4          False  \n",
      "8          False  \n",
      "22         False  \n",
      "743\n"
     ]
    }
   ],
   "source": [
    "## Pull the aliases that are sourced from GARD\n",
    "gard_alias = synonyms_df.loc[synonyms_df['source']=='GARD']\n",
    "\n",
    "## Filter the Wikidata GARD Alias table down to just the GARD IDs in GARD alias DF (ie- has allowable synonyms)\n",
    "gard_wd_limited_df = gard_alias_in_wd.loc[gard_alias_in_wd['diseaseId'].isin(gard_alias['diseaseId'].unique().tolist())]\n",
    "alias_check_df = gard_alias.merge(gard_wd_limited_df,on='diseaseId',how='inner').copy()\n",
    "\n",
    "## Check if the GARD synonym matches anything in the corresponding Wikidata label or alias\n",
    "alias_check_df['label_match?'] = alias_check_df['name'].str.lower()==alias_check_df['label'].str.lower()\n",
    "alias_check_df['alias_match?'] = alias_check_df['name'].str.lower()==alias_check_df['alias'].str.lower()\n",
    "\n",
    "## Identify the GARD synonyms that were found in Wikidata (label or aliases) for removal\n",
    "synonyms_to_drop = alias_check_df['name'].loc[(alias_check_df['label_match?']==True) | \n",
    "                                              (alias_check_df['alias_match?']==True)].unique().tolist()\n",
    "\n",
    "## Filter out GARD entries that were found in Wikidata\n",
    "synonyms_to_inspect = alias_check_df.loc[~alias_check_df['name'].isin(synonyms_to_drop)]\n",
    "\n",
    "## Identify the synonyms to add to wikidata as an alias\n",
    "synonyms_to_add = synonyms_to_inspect.drop_duplicates(subset=['diseaseId','name','source','WDID','label'], keep='first')\n",
    "print(synonyms_to_add.head(n=4))\n",
    "print(len(synonyms_to_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the GARD aliases to Wikidata\n",
    "Since Aliases don't allow for sourcing/referencing, include a edit comment that an alias from GARD was added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_qid = synonyms_to_add.iloc[0]['WDID']\n",
    "disease_alias = synonyms_to_add.iloc[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q21154057 Chromosome 15q11.2 microdeletion\n"
     ]
    }
   ],
   "source": [
    "print(disease_qid,disease_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15q11.2 microdeletion syndrome', 'CHROMOSOME 15q11.2 DELETION SYNDROME', 'Del(15)(q11.2)', 'Monosomy 15q11.2', 'Chromosome 15q11.2 microdeletion']\n",
      "1047775450\n"
     ]
    }
   ],
   "source": [
    "## Unit test --  write a statement\n",
    "wikidata_item = wdi_core.WDItemEngine(wd_item_id=disease_qid)\n",
    "wikidata_item.set_aliases([disease_alias],lang='en',append=True)\n",
    "wikidata_item.write(login, edit_summary='added alias from GARD')\n",
    "print(wikidata_item.get_aliases(lang='en'))\n",
    "print(wikidata_item.lastrevid)\n",
    "#wikidata_item.get_aliases(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script to run the synonym updates\n",
    "gard_alias_revision_list = []\n",
    "\n",
    "i=0\n",
    "for i in tqdm(range(len(gard_to_auto_add))):\n",
    "    disease_qid = synonyms_to_add.iloc[i]['WDID']\n",
    "    disease_alias = synonyms_to_add.iloc[i]['name']\n",
    "    wikidata_item = wdi_core.WDItemEngine(wd_item_id=disease_qid)\n",
    "    wikidata_item.set_aliases([disease_alias],lang='en',append=True)\n",
    "    wikidata_item.write(login, edit_summary='added alias from GARD')\n",
    "    gard_alias_revision_list.append(wikidata_item.lastrevid)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export the revision list \n",
    "with open('data/alias_revisions.txt','w') as aliaslog:\n",
    "    for eachrevid in gard_alias_revision_list:\n",
    "        aliaslog.write(str(eachrevid)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
