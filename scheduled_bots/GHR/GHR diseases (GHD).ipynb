{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Home Reference Data linking\n",
    "\n",
    "The Genetic Home Reference is an NLM resource and can be found at https://ghr.nlm.nih.gov/condition.\n",
    "\n",
    "The topics index can be accessed at: https://ghr.nlm.nih.gov/download/TopicIndex.xml\n",
    "\n",
    "An API call can be used to visit the topic and pulled the corresponding json document for each topic.  The json files will have various database identifiers which may be used to xref a condition to existing WD entities.\n",
    "\n",
    "The topic includes 'conditions', 'genes', 'chromosomes', and the 'handbook' itself. For the initial import, we're only interested in topics that are children of 'conditions'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidataintegrator import wdi_core, wdi_login, wdi_helpers\n",
    "from wikidataintegrator.ref_handlers import update_retrieved_if_new_multiple_refs\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import requests\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import ipywidgets \n",
    "import widgetsnbextension\n",
    "import xml.etree.ElementTree as et \n",
    "import time\n",
    "\n",
    "datasrc = 'https://ghr.nlm.nih.gov/download/TopicIndex.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Login for Scheduled bot\n",
    "print(\"Logging in...\")\n",
    "try:\n",
    "    from scheduled_bots.local import WDUSER, WDPASS\n",
    "except ImportError:\n",
    "    if \"WDUSER\" in os.environ and \"WDPASS\" in os.environ:\n",
    "        WDUSER = os.environ['WDUSER']\n",
    "        WDPASS = os.environ['WDPASS']\n",
    "    else:\n",
    "        raise ValueError(\"WDUSER and WDPASS must be specified in local.py or as environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in...\n",
      "https://www.wikidata.org/w/api.php\n",
      "Successfully logged in as Gtsulab\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"Logging in...\")\n",
    "import wdi_user_config ## Credentials stored in a wdi_user_config file\n",
    "login_dict = wdi_user_config.get_credentials()\n",
    "login = wdi_login.WDLogin(login_dict['WDUSER'], login_dict['WDPASS'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(datasrc)\n",
    "xml = r.text\n",
    "xtree = et.fromstring(xml)\n",
    "topic_of_interest = 'Conditions'\n",
    "\n",
    "for eachtopic in xtree.findall('topic'):\n",
    "    if eachtopic.attrib['id'] == topic_of_interest:\n",
    "        new_tree = eachtopic.find('topics')\n",
    "\n",
    "conditions = new_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6202\n",
      "                                  aka                    title  \\\n",
      "0                     10qter deletion  10q26 deletion syndrome   \n",
      "1  chromosome 10q26 deletion syndrome  10q26 deletion syndrome   \n",
      "\n",
      "                                                 url  \n",
      "0  https://ghr.nlm.nih.gov/condition/10q26-deleti...  \n",
      "1  https://ghr.nlm.nih.gov/condition/10q26-deleti...  \n"
     ]
    }
   ],
   "source": [
    "conditions_list = []\n",
    "\n",
    "for condition in conditions.findall('topic'):\n",
    "    title = condition.find('title').text\n",
    "    url = condition.find('url').text\n",
    "    try:\n",
    "        synonyms = condition.find('other_names')\n",
    "        for synonym in synonyms:\n",
    "            tmpdict = {'title': title,'url':url,'aka':synonym.text}\n",
    "            conditions_list.append(tmpdict)\n",
    "    except:\n",
    "        tmpdict = {'title': title,'url':url,'aka':'None'}\n",
    "        conditions_list.append(tmpdict)\n",
    "    \n",
    "conditions_df = pd.DataFrame(conditions_list)\n",
    "print(len(conditions_df))\n",
    "print(conditions_df.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2858496f104353bbed24cb2e012161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1301), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  code                memo                           topic  \\\n",
      "0   ad  autosomal dominant         10q26 deletion syndrome   \n",
      "1    n       not inherited  15q11-q13 duplication syndrome   \n",
      "\n",
      "                                                 url  \n",
      "0  https://ghr.nlm.nih.gov/condition/10q26-deleti...  \n",
      "1  https://ghr.nlm.nih.gov/condition/15q11-q13-du...  \n",
      "     db       key                    topic  \\\n",
      "0   GTR  C2674937  10q26 deletion syndrome   \n",
      "1  MeSH   D002872  10q26 deletion syndrome   \n",
      "\n",
      "                                                 url  \n",
      "0  https://ghr.nlm.nih.gov/condition/10q26-deleti...  \n",
      "1  https://ghr.nlm.nih.gov/condition/10q26-deleti...  \n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "              topic                                                url\n",
      "0  RAB18 deficiency  https://ghr.nlm.nih.gov/condition/rab18-defici...\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "conditions_url_list = conditions_df['url'].unique().tolist()\n",
    "condition_url_list_test = conditions_url_list[0:3]\n",
    "\n",
    "inher_list = []\n",
    "inher_fail = []\n",
    "syn_fail = []\n",
    "synonyms_df = pd.DataFrame(columns = ['topic','synonym'])\n",
    "xref_list = []\n",
    "xref_fail = []\n",
    "\n",
    "u=0\n",
    "for u in tqdm(range(len(conditions_url_list))):\n",
    "    eachurl = conditions_url_list[u]\n",
    "    tmpurl = eachurl+'?report=json'\n",
    "    tmpresponse = requests.get(tmpurl)\n",
    "    data = tmpresponse.json()\n",
    "    ## save the inheritance pattern data\n",
    "    try:\n",
    "        pattern_nos = data['inheritance-pattern-list']\n",
    "        i=0\n",
    "        while i < len(pattern_nos):\n",
    "            inher_dict = pattern_nos[i]['inheritance-pattern']\n",
    "            inher_dict['topic']=data['name']\n",
    "            inher_dict['url'] = eachurl\n",
    "            inher_list.append(inher_dict)\n",
    "            i=i+1\n",
    "    except:\n",
    "        inher_fail.append({'topic':data['name'],'url':eachurl})\n",
    "    \n",
    "    ## save the synonym list\n",
    "    try:\n",
    "        synlist = data['synonym-list']\n",
    "        syndf = pd.DataFrame(synlist)\n",
    "        syndf['topic']=data['name']\n",
    "        synonyms_df = pd.concat((synonyms_df,syndf),ignore_index=True)\n",
    "    except:\n",
    "        syn_fail.append({'topic':data['name'],'url':eachurl})\n",
    "    \n",
    "    ## save the xrefs\n",
    "    try:\n",
    "        xreflist = data['db-key-list']\n",
    "        k=0\n",
    "        while k < len(xreflist):\n",
    "            tmpdict = xreflist[k]['db-key']\n",
    "            tmpdict['topic'] = data['name']\n",
    "            tmpdict['url'] = eachurl\n",
    "            xref_list.append(tmpdict)\n",
    "            k=k+1\n",
    "    except:\n",
    "        xref_fail.append({'topic':data['name'],'url':eachurl})\n",
    "    u=u+1\n",
    "\n",
    "inheritance_df = pd.DataFrame(inher_list)\n",
    "inher_fail_df = pd.DataFrame(inher_fail)\n",
    "syn_fail_df = pd.DataFrame(syn_fail)\n",
    "xref_list_df = pd.DataFrame(xref_list)\n",
    "xref_fail_df = pd.DataFrame(xref_fail)\n",
    "print(inheritance_df.head(n=2))\n",
    "print(xref_list_df.head(n=2))\n",
    "print(inher_fail_df.head(n=2))\n",
    "print(syn_fail_df.head(n=2))\n",
    "print(xref_fail_df.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    RAB18 deficiency\n",
      "Name: topic, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(syn_fail_df['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GTR', 'MeSH', 'OMIM', 'Orphanet', 'SNOMED CT', 'GeneReviews', 'ICD-10-CM']\n"
     ]
    }
   ],
   "source": [
    "print(xref_list_df['db'].unique().tolist())\n",
    "## Corresponding Wikidata properties:\n",
    "wdprop_dict = {'MeSH':'P486','OMIM':'P492', 'Orphanet':'P1550', 'SNOMED CT':'P5806', 'GeneReviews':'P668', 'ICD-10-CM':'P4229'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Wikidata with corresponding information\n",
    "1. Identify the db identifier that has the fewest number of mapping issues\n",
    "2. Use identifiers to pull appropriate WD entry for each topic\n",
    "3. Check entry to see if mode of inheritance already added. If not, add it\n",
    "    -For inheritance statements, reference: Genetics Home Reference (Q62606821) \n",
    "4. Add url for GHR (need to create new property)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining identifier with fewest mapping issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original df size:  12874 de-duplicated url df size:  12868\n",
      "Number of unique urls:  1301\n",
      "Entries of each db:  db\n",
      "GTR            2513\n",
      "GeneReviews     814\n",
      "ICD-10-CM      2094\n",
      "MeSH           1441\n",
      "OMIM           2752\n",
      "Orphanet       1436\n",
      "SNOMED CT      1824\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Drop topics that map to the same url (assuming they're synonyms)\n",
    "xref_no_dups = xref_list_df.drop_duplicates()\n",
    "print(\"original df size: \",len(xref_list_df),\"de-duplicated url df size: \",len(xref_no_dups))\n",
    "\n",
    "## Check coverage of identifiers for the unique urls\n",
    "xref_dups = xref_list_df.groupby(['db','key']).size().reset_index(name='count')\n",
    "print(\"Number of unique urls: \",len(xref_no_dups['url'].unique().tolist()))\n",
    "print(\"Entries of each db: \",xref_list_df.groupby('db').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTR:  1284\n",
      "GeneReviews:  700\n",
      "ICD-10-CM:  501\n",
      "MeSH:  1301\n",
      "OMIM:  1254\n",
      "Orphanet:  1169\n",
      "SNOMED CT:  1237\n"
     ]
    }
   ],
   "source": [
    "## Verify coverage\n",
    "print('GTR: ',len(xref_list_df.loc[xref_list_df['db']=='GTR'].groupby(['db','url']).size()))\n",
    "print('GeneReviews: ',len(xref_list_df.loc[xref_list_df['db']=='GeneReviews'].groupby(['db','url']).size()))\n",
    "print('ICD-10-CM: ',len(xref_list_df.loc[xref_list_df['db']=='ICD-10-CM'].groupby(['db','url']).size()))\n",
    "print('MeSH: ',len(xref_list_df.loc[xref_list_df['db']=='MeSH'].groupby(['db','url']).size()))\n",
    "print('OMIM: ',len(xref_list_df.loc[xref_list_df['db']=='OMIM'].groupby(['db','url']).size()))\n",
    "print('Orphanet: ',len(xref_list_df.loc[xref_list_df['db']=='Orphanet'].groupby(['db','url']).size()))\n",
    "print('SNOMED CT: ',len(xref_list_df.loc[xref_list_df['db']=='SNOMED CT'].groupby(['db','url']).size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the database that is closest in number to the number of unique urls is Orphanet and MeSH, suggesting that these may have the fewest mapping issues within the data set, as GTR (Genetics Testing Registry) and OMIM may have multiple identifiers mapping to the same topic/url. GeneReviews has fewer suggesting that there are entries either missing GeneReview mappings, or that there are multiple urls mapping to a single GeneReview ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicated identifiers by type: \n",
      "            db  dup_counts\n",
      "0          GTR          26\n",
      "1  GeneReviews          70\n",
      "2    ICD-10-CM         131\n",
      "3         MeSH         182\n",
      "4         OMIM          60\n",
      "5     Orphanet          32\n",
      "6    SNOMED CT          25\n",
      "Number of entries affected by duplicated identfiers: \n",
      "            db  entry_counts\n",
      "0          GTR            54\n",
      "1  GeneReviews           206\n",
      "2    ICD-10-CM           292\n",
      "3         MeSH           820\n",
      "4         OMIM           122\n",
      "5     Orphanet            77\n",
      "6    SNOMED CT            56\n"
     ]
    }
   ],
   "source": [
    "#Investigate duplicate mappings more closely.\n",
    "dups = xref_dups.loc[xref_dups['count']>1]\n",
    "print(\"number of duplicated identifiers by type: \")\n",
    "print(dups.groupby('db').size().reset_index(name='dup_counts'))\n",
    "print(\"Number of entries affected by duplicated identfiers: \")\n",
    "print(dups.groupby('db')['count'].sum().reset_index(name='entry_counts'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of unique coverage, it looks like Orphanet will be the least problematic to use. Now to check it's coverage in Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orphanet Xref list:  1435 Orphanet Xref list less dups:  1169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d4ee79e30a455d99108da0bb0603e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1169), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "resulting mapping table has:  1112  rows.\n"
     ]
    }
   ],
   "source": [
    "## Generate list of unique Orphanet IDs\n",
    "orphanet_ghr = xref_no_dups.loc[xref_no_dups['db']=='Orphanet']\n",
    "no_orphanet_dups = orphanet_ghr.drop_duplicates('url')\n",
    "print(\"Original Orphanet Xref list: \", len(orphanet_ghr), \"Orphanet Xref list less dups: \",len(no_orphanet_dups))\n",
    "orphanet_id_list = no_orphanet_dups['key'].tolist()\n",
    "\n",
    "# Retrieve the QIDs for each Orphanet ID (The property for Orphanet IDs is P1550)\n",
    "i=0\n",
    "wdmap = []\n",
    "wdmapfail = []\n",
    "for i in tqdm(range(len(orphanet_id_list))):\n",
    "    orph_id = orphanet_id_list[i]\n",
    "    try:\n",
    "        sparqlQuery = \"SELECT * WHERE {?topic wdt:P1550 \\\"\"+orph_id+\"\\\"}\"\n",
    "        result = wdi_core.WDItemEngine.execute_sparql_query(sparqlQuery)\n",
    "        orpha_qid = result[\"results\"][\"bindings\"][0][\"topic\"][\"value\"].replace(\"http://www.wikidata.org/entity/\", \"\")\n",
    "        wdmap.append({'Orphanet':orph_id,'WDID':orpha_qid})\n",
    "    except:\n",
    "        wdmapfail.append(orph_id)\n",
    "    i=i+1\n",
    "\n",
    "## Inspect the results for mapping or coverage issues\n",
    "wdid_orpha_df = pd.DataFrame(wdmap)\n",
    "print(\"resulting mapping table has: \",len(wdid_orpha_df),\" rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding mode of inheritance data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the inheritance data for mapping\n",
    "1. De-duplicate Orphanet-Wikidata mapping table as needed\n",
    "2. Merge inheritance table to mapping table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de-duplicated table:  1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ginger\\anaconda3\\envs\\pywikibot\\lib\\site-packages\\pandas\\core\\frame.py:2746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resulting mapped table:  1339\n"
     ]
    }
   ],
   "source": [
    "## De-duplicate to remove anything with mapping issues\n",
    "wd_orpha_no_dups = wdid_orpha_df.drop_duplicates('Orphanet').copy()\n",
    "wd_orpha_no_dups.drop_duplicates('WDID')\n",
    "print('de-duplicated table: ',len(wd_orpha_no_dups))\n",
    "\n",
    "## Merge with Inheritance table\n",
    "no_orphanet_dups.rename(columns={'key':'Orphanet'}, inplace=True)\n",
    "inher_wd_db = inheritance_df.merge(wd_orpha_no_dups.merge(no_orphanet_dups,on='Orphanet',how='inner'), on=['url','topic'], how='inner')\n",
    "print(\"resulting mapped table: \",len(inher_wd_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the references and write the data to Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code  memo                \n",
      "ac    autosomal codominant      4\n",
      "ad    autosomal dominant      555\n",
      "ar    autosomal recessive     633\n",
      "m     mitochondrial            15\n",
      "n     not inherited           103\n",
      "u     pattern unknown         111\n",
      "x     X-linked                 21\n",
      "xd    X-linked dominant        41\n",
      "xr    X-linked recessive       81\n",
      "y     Y-linked                  2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(inheritance_df.groupby(['code','memo']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mode of inheritance = P1199\n",
    "GHR_WD_codes = {'ac': 'Q13169788', ##wd:Q13169788 (codominant)\n",
    "               'ad': 'Q116406', ##wd:Q116406 (autosomal dominant)\n",
    "               'ar': 'Q15729064', ##wd:Q15729064 (autosomal recessive)\n",
    "               'm': 'Q15729075', ##wd:Q15729075 (mitochondrial)\n",
    "               'x': 'Q70899378', #wd:Q2597344 (X-linked inheritance)\n",
    "               'xd': 'Q3731276', ##wd:Q3731276 (X-linked dominant)\n",
    "               'xr': 'Q1988987', ##wd:Q1988987 (X-linked recessive)\n",
    "               'y': 'Q2598585'} ##wd:Q2598585 (Y linkage)\n",
    "\n",
    "GHR_codes_no_WD = {'n': 'not inherited', 'u': 'unknown pattern'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import copy\n",
    "def create_reference(ghr_url):\n",
    "    refStatedIn = wdi_core.WDItemID(value=\"Q62606821\", prop_nr=\"P248\", is_reference=True)\n",
    "    timeStringNow = datetime.now().strftime(\"+%Y-%m-%dT00:00:00Z\")\n",
    "    refRetrieved = wdi_core.WDTime(timeStringNow, prop_nr=\"P813\", is_reference=True)\n",
    "    refURL = wdi_core.WDUrl(value=ghr_url, prop_nr=\"P854\", is_reference=True)\n",
    "\n",
    "    return [refStatedIn, refRetrieved, refURL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193\n"
     ]
    }
   ],
   "source": [
    "## Limit adding mode of inheritance statements to diseases with known modes of inheritance\n",
    "inheritance_avail = inher_wd_db.loc[(inher_wd_db['code']!='n')&(inher_wd_db['code']!='u')]\n",
    "print(len(inheritance_avail))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q21154055\n",
      "<wikidataintegrator.wdi_core.WDItemEngine object at 0x000000000A3FAEF0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Q21154055'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Unit test-- write a single statement\n",
    "\"\"\"\n",
    "disease_qid = inheritance_avail.iloc[0]['WDID']\n",
    "inheritance_method = GHR_WD_codes[inheritance_avail.iloc[0]['code']]\n",
    "ghr_url = inheritance_avail.iloc[0]['url']\n",
    "reference = create_reference(ghr_url)\n",
    "statement = [wdi_core.WDItemID(value=inheritance_method, prop_nr=\"P1199\", references=[copy.deepcopy(reference)])]\n",
    "\n",
    "item = wdi_core.WDItemEngine(wd_item_id=disease_qid, data=statement, append_value=\"P1199\",\n",
    "                       global_ref_mode='CUSTOM', ref_handler=update_retrieved_if_new_multiple_refs)\n",
    "print(disease_qid)\n",
    "print(item)\n",
    "item.write(login)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fc117abb3144b5b74f36fe8ea90482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### test run -- write 10 statements\n",
    "\"\"\"\n",
    "i=0\n",
    "for i in tqdm(range(10)):\n",
    "    disease_qid = inheritance_avail.iloc[i]['WDID']\n",
    "    inheritance_method = GHR_WD_codes[inheritance_avail.iloc[i]['code']]\n",
    "    ghr_url = inheritance_avail.iloc[i]['url']\n",
    "    reference = create_reference(ghr_url)\n",
    "    statement = [wdi_core.WDItemID(value=inheritance_method, prop_nr=\"P1199\", references=[copy.deepcopy(reference)])]\n",
    "    item = wdi_core.WDItemEngine(wd_item_id=disease_qid, data=statement, append_value=\"P1199\",\n",
    "                           global_ref_mode='CUSTOM', ref_handler=update_retrieved_if_new_multiple_refs)\n",
    "    item.write(login)\n",
    "    time.sleep(2)\n",
    "    i=i+1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for i in tqdm(range(len(inheritance_avail))):\n",
    "    disease_qid = inheritance_avail.iloc[i]['WDID']\n",
    "    inheritance_method = GHR_WD_codes[inheritance_avail.iloc[i]['code']]\n",
    "    ghr_url = inheritance_avail.iloc[i]['url']\n",
    "    reference = create_reference(ghr_url)\n",
    "    statement = [wdi_core.WDItemID(value=inheritance_method, prop_nr=\"P1199\", references=[copy.deepcopy(reference)])]\n",
    "    item = wdi_core.WDItemEngine(wd_item_id=disease_qid, data=statement, append_value=\"P1199\",\n",
    "                           global_ref_mode='CUSTOM', ref_handler=update_retrieved_if_new_multiple_refs)\n",
    "    item.write(login)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the urls to separate property for external linking\n",
    "This portion is awaiting completion of the property creation and approval process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Orphanet       WDID        db                           topic  \\\n",
      "0    96148  Q21154055  Orphanet         10q26 deletion syndrome   \n",
      "1     3306   Q2703116  Orphanet  15q11-q13 duplication syndrome   \n",
      "\n",
      "                                                 url  \n",
      "0  https://ghr.nlm.nih.gov/condition/10q26-deleti...  \n",
      "1  https://ghr.nlm.nih.gov/condition/15q11-q13-du...  \n"
     ]
    }
   ],
   "source": [
    "## Load successfully mapped GHR disease urls\n",
    "mapped_orpha_urls = wd_orpha_no_dups.merge(no_orphanet_dups,on='Orphanet',how='inner')\n",
    "print(mapped_orpha_urls.head(n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10q26-deletion-syndrome\n"
     ]
    }
   ],
   "source": [
    "## Unit test --  write a statement\n",
    "disease_qid = mapped_orpha_urls.iloc[0]['WDID']\n",
    "ghr_url = mapped_orpha_urls.iloc[0]['url']\n",
    "ghr_id = mapped_orpha_urls.iloc[0]['url'].replace(\"https://ghr.nlm.nih.gov/condition/\",\"\")\n",
    "reference = create_reference(ghr_url)\n",
    "url_prop = \"PXXX\" ## to be filled in once a property is assigned\n",
    "statement = [wdi_core.WDString(value=ghr_id, prop_nr=url_prop, references=[copy.deepcopy(reference)])]\n",
    "item = wdi_core.WDItemEngine(wd_item_id=disease_qid, data=statement, append_value=url_prop,\n",
    "                           global_ref_mode='CUSTOM', ref_handler=update_retrieved_if_new_multiple_refs)\n",
    "\n",
    "print(ghr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for i in tqdm(range(len(mapped_orpha_urls))):\n",
    "    disease_qid = mapped_orpha_urls.iloc[i]['WDID']\n",
    "    ghr_url = mapped_orpha_urls.iloc[i]['url']\n",
    "    ghr_id = mapped_orpha_urls.iloc[0]['url'].replace(\"https://ghr.nlm.nih.gov/condition/\",\"\")\n",
    "    reference = create_reference(ghr_url)\n",
    "    url_prop = \"PXXX\" ## to be filled in once a property is assigned\n",
    "    statement = [wdi_core.WDString(value=ghr_id, prop_nr=url_prop, references=[copy.deepcopy(reference)])]\n",
    "    item = wdi_core.WDItemEngine(wd_item_id=disease_qid, data=statement, append_value=url_prop,\n",
    "                               global_ref_mode='CUSTOM', ref_handler=update_retrieved_if_new_multiple_refs)\n",
    "    item.write(login)\n",
    "    i=i+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
